{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_root = 'drumData/'\n",
    "sr = 48000 # this is the samplerate initially used to load the samples\n",
    "total_limit = 100 #None # set this to 100 to export 100 samples\n",
    "length_limit = sr/4 # set this to sr/4 to only export 250ms of audio per sample\n",
    "downsampling_factor = 4\n",
    "drumSprites = {}\n",
    "limit = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "from utils import ffmpeg_save_audio\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "import time as timeMod\n",
    "import scipy.spatial\n",
    "import scipy.spatial.distance as dist \n",
    "import itertools\n",
    "from utils import *\n",
    "from datetime import datetime\n",
    "from time import mktime\n",
    "from time import time\n",
    "from sklearn.decomposition import PCA\n",
    "#%time samples = np.load(join(data_root, 'samples.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 464 µs, sys: 227 ms, total: 227 ms\n",
      "Wall time: 355 ms\n",
      "CPU times: user 636 µs, sys: 18.6 ms, total: 19.2 ms\n",
      "Wall time: 26.5 ms\n",
      "CPU times: user 513 µs, sys: 104 ms, total: 104 ms\n",
      "Wall time: 151 ms\n",
      "CPU times: user 1.12 ms, sys: 58.5 ms, total: 59.7 ms\n",
      "Wall time: 80.1 ms\n",
      "CPU times: user 528 µs, sys: 7.49 ms, total: 8.02 ms\n",
      "Wall time: 11.1 ms\n",
      "CPU times: user 473 µs, sys: 9.96 ms, total: 10.4 ms\n",
      "Wall time: 15.3 ms\n",
      "CPU times: user 546 µs, sys: 30.4 ms, total: 31 ms\n",
      "Wall time: 57.3 ms\n"
     ]
    }
   ],
   "source": [
    "drumNames = pickle.load(open(data_root+'drumNames.pickle'))\n",
    "drumLengths = pickle.load(open(data_root+'drumLengths.pickle'))\n",
    "drumFingerPrints = {}\n",
    "drumSamples = {}\n",
    "for d in drumNames:\n",
    "    %time drumSamples[d] = np.load(join(data_root, d+'_samples.npy'))\n",
    "colors = ['#000000', '#ff0000', '#00ff00', '#0000ff', '#ffff00', '#ff00ff', '#00ffff']\n",
    "initial_dims = [30]\n",
    "perplexities = [30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute sprites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated spritesheet print for kick (5158, 3000)\n",
      "generated spritesheet print for tom (422, 3000)\n",
      "generated spritesheet print for snare (2546, 3000)\n",
      "generated spritesheet print for clap (1324, 3000)\n",
      "generated spritesheet print for hi.hat (159, 3000)\n",
      "generated spritesheet print for ride (228, 3000)\n",
      "generated spritesheet print for crash (723, 3000)\n"
     ]
    }
   ],
   "source": [
    "# take a sample, crop it, and down sample it\n",
    "def job(samp, length_limit, downsampling_factor):\n",
    "    shortSamp = samp[:length_limit]\n",
    "    if len(shortSamp) < length_limit:\n",
    "        shortSamp = np.pad(shortSamp, (0, length_limit-len(shortSamp)), 'constant', constant_values=0)\n",
    "    downShortSamp = np.interp(np.arange(0, length_limit, downsampling_factor), np.arange(0, length_limit), shortSamp)\n",
    "    return downShortSamp\n",
    "\n",
    "def calculateSprites(length_limit, downsampling_factor):\n",
    "    _drumSprites = {}\n",
    "    for d in drumNames:\n",
    "        y = drumSamples[d]\n",
    "        sprites = map(lambda samp: job(samp, length_limit, downsampling_factor), drumSamples[d][:limit])\n",
    "        sprites = np.asarray(sprites).astype(np.float32)\n",
    "        _drumSprites[d] = sprites\n",
    "        print \"generated spritesheet print for\", d, sprites.shape\n",
    "    return _drumSprites\n",
    "\n",
    "drumSprites = calculateSprites(length_limit, downsampling_factor)\n",
    "data = np.concatenate([drumSprites[d] for d in drumNames])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define TSNE calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2d_inspect = None\n",
    "\n",
    "def save_data(data, fn):\n",
    "    np.savetxt(fn, data, fmt='%.5f', delimiter='\\t')\n",
    "\n",
    "def savePlotsAndData(newData, data_root, prefix, colorMap, dataDir, plotDir, initial_dims=30, perplexity=30):    \n",
    "    figsize = (16,16)\n",
    "    pointsize = 30\n",
    "    \n",
    "    struct = timeMod.localtime(time())\n",
    "    dt = datetime.fromtimestamp(mktime(struct))\n",
    "    \n",
    "    save_data(newData, join(data_root, dataDir+'/{}.{}.{}.2d - {}.tsv'.format(prefix, initial_dims, perplexity, dt)))\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.scatter(newData[:,0], newData[:,1], c=colorMap, s=pointsize)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(join(data_root, plotDir+'/{}.{}.{}_2D - {}.png'.format(prefix, initial_dims, perplexity, dt)))\n",
    "    plt.close()\n",
    "    \n",
    "def tsne(data, data_root, prefix, colorMap, initial_dims=30, perplexity=30):\n",
    "    mkdir_p(data_root + 'tsne')\n",
    "    mkdir_p(data_root + 'plot')\n",
    "    \n",
    "    print initial_dims, perplexity, type(data), data.shape, data.dtype\n",
    "    X_2d = list(bh_tsne(data, initial_dims=initial_dims, perplexity=perplexity, no_dims=2, verbose=True))\n",
    "    X_2d = normalize(np.array(X_2d))\n",
    "    \n",
    "    savePlotsAndData(X_2d, data_root, prefix, colorMap, 'tsne', 'plot', initial_dims, perplexity)\n",
    "    \n",
    "    return X_2d\n",
    "\n",
    "def pca(data, data_root, prefix, colorMap):\n",
    "    mkdir_p(data_root + 'pca')\n",
    "    mkdir_p(data_root + 'pcaPlot')\n",
    "    \n",
    "    pcaInstance = PCA(n_components=2)  \n",
    "    X_2d = pcaInstance.fit_transform(data)\n",
    "    \n",
    "    savePlotsAndData(X_2d, data_root, prefix, colorMap, 'pca', 'pcaPlot')\n",
    "    \n",
    "    return X_2d\n",
    "\n",
    "    \n",
    "def concatColors(segmentList, colorList):\n",
    "    multiples = []\n",
    "    #print segmentList, colorList\n",
    "    for i in range(len(segmentList)):\n",
    "        multiples.append([colorList[i]]*segmentList[i])\n",
    "    return list(itertools.chain(*multiples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 <type 'numpy.ndarray'> (10560, 3000) float64\n",
      "initial_dims=30, perplexity=30, 167.770179987 seconds\n"
     ]
    }
   ],
   "source": [
    "data = data.astype(np.float64)\n",
    "colorMap = concatColors(drumLengths, colors)\n",
    "useTsne = True\n",
    "prefix = 'sprites'\n",
    "def job(params):\n",
    "    start = time()\n",
    "    tsne2d = tsne(data, data_root, prefix, colorMap, initial_dims=params[0], perplexity=params[1])\n",
    "    pca2d = pca(data, data_root, prefix, colorMap)\n",
    "    print 'initial_dims={}, perplexity={}, {} seconds'.format(params[0], params[1], time() - start)\n",
    "    return [tsne2d, pca2d]\n",
    "params = list(itertools.product(initial_dims, perplexities))\n",
    "pool = Pool()\n",
    "dimReducedArrays = pool.map(job, params)\n",
    "newData = dimReducedArrays[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create point -> class hashmap\n",
    "def getClassesPerSample(data):\n",
    "    drumClasses = {}\n",
    "    classIndex = 0\n",
    "    for i in range(len(data)):\n",
    "        if sum(drumLengths[0:classIndex+1]) <= i:\n",
    "            classIndex += 1\n",
    "        drumClasses[tuple(data[i])] = drumNames[classIndex]\n",
    "    return drumClasses\n",
    "\n",
    "drumClasses = getClassesPerSample(data)\n",
    "\n",
    "numNeighbors = 10\n",
    "\n",
    "## Arguments\n",
    "## data -    an array of length n where array[i] is the fraction of neighbors of point i \n",
    "#            had the same class as point i.\n",
    "# numPerClass - Assumes that points from the same class are contiguous and in\n",
    "#            the same order as drumNames. Should use drumLengths for this parameter\n",
    "# calcFunc - The summary statistic you want to calcuate per class (mean, medain, etc)\n",
    "def calculateFuncPerClass(data, numPerClass, calcFunc):\n",
    "    segments = [0]+numPerClass\n",
    "    for i in range(1, len(segments)):\n",
    "        segments[i] = segments[i] + segments[i-1]\n",
    "    valuesPerClass = []\n",
    "    for i in range(len(segments)-1):\n",
    "        valuesPerClass.append(calcFunc(data[segments[i]:segments[i+1]]))\n",
    "    return valuesPerClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pairwise distance implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pairwise distances calculated 1.07847809792\n",
      "partitions calculated 2.96025514603\n",
      "knn classes calculated 29.0214810371\n",
      "pairwise distances calculated 0.878396987915\n",
      "partitions calculated 2.18531298637\n",
      "knn classes calculated 27.8770859241\n",
      "pairwise distances calculated 369.047304153\n",
      "partitions calculated 370.24468708\n",
      "knn classes calculated 395.923006058\n"
     ]
    }
   ],
   "source": [
    "#using https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.spatial.distance.cdist.html\n",
    "#and argpartition from - https://stackoverflow.com/questions/6910641/how-to-get-indices-of-n-maximum-values-in-a-numpy-array\n",
    "\n",
    "## Arguments - pointData is m x n np array, with n points of m dimensions\n",
    "# pointD numNeighbors is the number of nearest neighbors for which to compare classes\n",
    "#\n",
    "## returns - an array of length n where array[i] is the fraction of neighbors of point i \n",
    "#            had the same class as point i\n",
    "def calculateKNNClassAccuracy(pointData, numNeighbors, printTimes=False):\n",
    "    startTime = timeMod.time()\n",
    "    pairwiseDist = dist.cdist(pointData, pointData)\n",
    "    if printTimes:\n",
    "        print \"pairwise distances calculated\", timeMod.time() - startTime\n",
    "    kPartition = np.argpartition(pairwiseDist, -numNeighbors)\n",
    "    if printTimes:\n",
    "        print \"partitions calculated\", timeMod.time() - startTime\n",
    "    fracSameNeighborClasses = np.zeros((len(data)))\n",
    "    \n",
    "    for i in range(len(pairwiseDist)):\n",
    "        neighborIndexes = kPartition[i][-numNeighbors:]\n",
    "        neighbors = [data[ind] for ind in neighborIndexes]\n",
    "        \n",
    "        sampleClass = drumClasses[tuple(data[i])]\n",
    "        neighborClasses = [drumClasses[tuple(neighbor)] for neighbor in neighbors]\n",
    "        numSameNeighborClasses = len(filter(lambda c : c == sampleClass, neighborClasses))\n",
    "        fracSameNeighborClasses[i] = numSameNeighborClasses * 1.0 / numNeighbors\n",
    "    \n",
    "    if printTimes:\n",
    "        print \"knn classes calculated\", timeMod.time() - startTime\n",
    "        \n",
    "    return fracSameNeighborClasses\n",
    "\n",
    "classAccuracies_LD_TSNE = calculateKNNClassAccuracy(newData[0], numNeighbors, True)\n",
    "classAccuracies_LD_PCA = calculateKNNClassAccuracy(newData[0], numNeighbors, True)\n",
    "classAccuracies_HD = calculateKNNClassAccuracy(data, numNeighbors, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean for highDim, tsne, pca\n",
      "0.469 0.231 0.231\n",
      "\n",
      "std for highDim, tsne, pca\n",
      "0.475 0.401 0.401\n",
      "\n",
      "mean per class for highDim\n",
      "[0.953, 0.095, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "std per class for highDim\n",
      "[0.465, 0.017, 0.027, 0.029, 0.0, 0.0, 0.051]\n",
      "\n",
      "mean per class for tsne\n",
      "[0.47, 0.002, 0.002, 0.003, 0.0, 0.0, 0.004]\n",
      "\n",
      "std per class for tsne\n",
      "[0.052, 0.023, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "mean per class for pca\n",
      "[0.47, 0.002, 0.002, 0.003, 0.0, 0.0, 0.004]\n",
      "\n",
      "std per class for pca\n",
      "[0.465, 0.017, 0.027, 0.029, 0.0, 0.0, 0.051]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"mean for highDim, tsne, pca\"\n",
    "print round(np.mean(classAccuracies_HD), 3), round(np.mean(classAccuracies_LD_TSNE), 3), round(np.mean(classAccuracies_LD_PCA), 3)\n",
    "print\n",
    "\n",
    "print \"std for highDim, tsne, pca\"\n",
    "print round(np.std(classAccuracies_HD), 3), round(np.std(classAccuracies_LD_TSNE), 3), round(np.std(classAccuracies_LD_PCA), 3)\n",
    "print\n",
    "\n",
    "print \"mean per class for highDim\"\n",
    "print [round(n, 3) for n in calculateFuncPerClass(classAccuracies_HD, drumLengths, np.mean)]\n",
    "print \n",
    "\n",
    "print \"std per class for highDim\"\n",
    "print [round(n, 3) for n in calculateFuncPerClass(classAccuracies_LD_TSNE, drumLengths, np.std)]\n",
    "print\n",
    "\n",
    "print \"mean per class for tsne\"\n",
    "print [round(n, 3) for n in calculateFuncPerClass(classAccuracies_LD_TSNE, drumLengths, np.mean)]\n",
    "print \n",
    "\n",
    "print \"std per class for tsne\"\n",
    "print [round(n, 3) for n in calculateFuncPerClass(classAccuracies_HD, drumLengths, np.std)]\n",
    "print\n",
    "\n",
    "print \"mean per class for pca\"\n",
    "print [round(n, 3) for n in calculateFuncPerClass(classAccuracies_LD_PCA, drumLengths, np.mean)]\n",
    "print \n",
    "\n",
    "print \"std per class for pca\"\n",
    "print [round(n, 3) for n in calculateFuncPerClass(classAccuracies_LD_PCA, drumLengths, np.std)]\n",
    "print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
