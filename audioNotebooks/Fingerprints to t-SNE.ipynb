{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This converts `fingerprints.npy` to `.tsv` formatted t-SNE embeddings and plots of those embeddings in the `tsne/` and `plot/` folders respectively. If you add multiple values to `perplexity` and `initial_dims` then all combinations will be computed (in parallel). Good perplexities are in the range 1-200 with the best range around 30-100. Good `initial_dims` are in the range 30 and higher, with the dimensionality of your input data being the highest possible value (e.g., a 32x32 fingerprint would have a highest possible `initial_dims` value of 32x32=1024).\n",
    "\n",
    "Change the \"mode\" to try different t-SNE variations.\n",
    "* \"fingerprints\" will only use `fingerprints.npy`\n",
    "* \"predicted_labels\" will only use `predicted_labels.npy`\n",
    "* \"predicted_encoding\" will only use `predicted_encoding.npy`\n",
    "* \"combined\" will use all of the above data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to do:\n",
    "- Normalize audio\n",
    "- Scale the spectrogram\n",
    "- do all of the data cleaning so different factors between sample banks don't bias the feature extraction\n",
    "- make sure to baseline this against traditional feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "from utils import *\n",
    "from os.path import join\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time as timeMod\n",
    "from time import mktime\n",
    "from datetime import datetime\n",
    "import scipy.spatial\n",
    "import scipy.spatial.distance as dist \n",
    "import pickle\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'drumData/'\n",
    "initial_dims = [30]\n",
    "perplexities = [30]\n",
    "mode = 'fingerprints'\n",
    "drumNames = pickle.load(open(data_root+'drumNames.pickle'))\n",
    "drumLengths = pickle.load(open(data_root+'drumLengths.pickle'))\n",
    "colors = ['#000000', '#ff0000', '#00ff00', '#0000ff', '#ffff00', '#ff00ff', '#00ffff']\n",
    "# mode = 'predicted_labels'\n",
    "# mode = 'predicted_encoding'\n",
    "# mode = 'combined'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define TSNE calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2d_inspect = None\n",
    "\n",
    "def save_data(data, fn):\n",
    "    np.savetxt(fn, data, fmt='%.5f', delimiter='\\t')\n",
    "\n",
    "def savePlotsAndData(newData, data_root, prefix, colorMap, dataDir, plotDir, initial_dims=30, perplexity=30):    \n",
    "    figsize = (16,16)\n",
    "    pointsize = 30\n",
    "    \n",
    "    struct = timeMod.localtime(time())\n",
    "    dt = datetime.fromtimestamp(mktime(struct))\n",
    "    \n",
    "    save_data(newData, join(data_root, dataDir+'/{}.{}.{}.2d - {}.tsv'.format(prefix, initial_dims, perplexity, dt)))\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.scatter(newData[:,0], newData[:,1], c=colorMap, s=pointsize)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(join(data_root, plotDir+'/{}.{}.{}_2D - {}.png'.format(prefix, initial_dims, perplexity, dt)))\n",
    "    plt.close()\n",
    "    \n",
    "def tsne(data, data_root, prefix, colorMap, initial_dims=30, perplexity=30):\n",
    "    mkdir_p(data_root + 'tsne')\n",
    "    mkdir_p(data_root + 'plot')\n",
    "    \n",
    "    print initial_dims, perplexity, type(data), data.shape, data.dtype\n",
    "    X_2d = list(bh_tsne(data, initial_dims=initial_dims, perplexity=perplexity, no_dims=2, verbose=True))\n",
    "    X_2d = normalize(np.array(X_2d))\n",
    "    \n",
    "    savePlotsAndData(X_2d, data_root, prefix, colorMap, 'tsne', 'plot')\n",
    "    \n",
    "    return X_2d\n",
    "\n",
    "def pca(data, data_root, prefix, colorMap):\n",
    "    mkdir_p(data_root + 'pca')\n",
    "    mkdir_p(data_root + 'pcaPlot')\n",
    "    \n",
    "    pcaInstance = PCA(n_components=2)  \n",
    "    X_2d = pcaInstance.fit_transform(data)\n",
    "    \n",
    "    savePlotsAndData(X_2d, data_root, prefix, colorMap, 'pca', 'pcaPlot')\n",
    "    \n",
    "    return X_2d\n",
    "\n",
    "    \n",
    "def concatColors(segmentList, colorList):\n",
    "    multiples = []\n",
    "    #print segmentList, colorList\n",
    "    for i in range(len(segmentList)):\n",
    "        multiples.append([colorList[i]]*segmentList[i])\n",
    "    return list(itertools.chain(*multiples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fingerprint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and normalize any dataset we need\n",
    "if mode == 'fingerprints' or mode == 'combined':\n",
    "    drumPrints = []\n",
    "    for drum in drumNames:\n",
    "        drumPrints.append(np.load(join(data_root, drum+'_fingerprints.npy')))\n",
    "        #print drum, drumPrints[-1].shape\n",
    "    drumLengths = [drumPrint.shape[0] for drumPrint in drumPrints]\n",
    "    colorMap = concatColors(drumLengths, colors)\n",
    "    fingerprints = np.vstack(drumPrints)\n",
    "    fingerprints = fingerprints.reshape(len(fingerprints), -1)\n",
    "if mode == 'predicted_labels' or mode == 'combined':\n",
    "    predicted_labels = np.load(join(data_root, 'predicted_labels.npy'))\n",
    "    predicted_labels -= predicted_labels.min()\n",
    "    predicted_labels /= predicted_labels.max()\n",
    "if mode == 'predicted_encoding' or mode == 'combined':\n",
    "    predicted_encoding = np.load(join(data_root, 'predicted_encoding.npy'))\n",
    "    std = predicted_encoding.std(axis=0)\n",
    "    predicted_encoding = predicted_encoding[:, std > 0] / std[std > 0]\n",
    "    \n",
    "if mode == 'fingerprints':\n",
    "    data = fingerprints\n",
    "if mode == 'predicted_labels':\n",
    "    data = predicted_labels\n",
    "if mode == 'predicted_encoding':\n",
    "    data = predicted_encoding\n",
    "if mode == 'combined':\n",
    "    data = np.hstack((fingerprints, predicted_labels, predicted_encoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 <type 'numpy.ndarray'> (10560, 1024) float64\n",
      "initial_dims=30, perplexity=30, 136.524546862 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-9:\n",
      "Process PoolWorker-13:\n",
      "Process PoolWorker-14:\n",
      "Process PoolWorker-10:\n",
      "Process PoolWorker-16:\n",
      "Process PoolWorker-15:\n",
      "Process PoolWorker-11:\n",
      "Process PoolWorker-12:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    racquire()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    task = get()\n",
      "    racquire()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "KeyboardInterrupt\n",
      "    task = get()\n",
      "    task = get()\n",
      "    racquire()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    return recv()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "data = data.astype(np.float64)\n",
    "colorMap = concatColors(drumLengths, colors)\n",
    "useTsne = True\n",
    "prefix = 'fingerprints'\n",
    "def job(params):\n",
    "    start = time()\n",
    "    tsne2d = tsne(data, data_root, prefix, colorMap, initial_dims=params[0], perplexity=params[1])\n",
    "    pca2d = pca(data, data_root, prefix, colorMap)\n",
    "    print 'initial_dims={}, perplexity={}, {} seconds'.format(params[0], params[1], time() - start)\n",
    "    return [tsne2d, pca2d]\n",
    "params = list(itertools.product(initial_dims, perplexities))\n",
    "pool = Pool()\n",
    "dimReducedArrays = pool.map(job, params)\n",
    "newData = dimReducedArrays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dimReducedArrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric calculation implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create point -> class hashmap\n",
    "def getClassesPerSample(data):\n",
    "    drumClasses = {}\n",
    "    classIndex = 0\n",
    "    for i in range(len(data)):\n",
    "        if sum(drumLengths[0:classIndex+1]) <= i:\n",
    "            classIndex += 1\n",
    "        drumClasses[tuple(data[i])] = drumNames[classIndex]\n",
    "    return drumClasses\n",
    "\n",
    "drumClasses = getClassesPerSample(data)\n",
    "\n",
    "numNeighbors = 10\n",
    "\n",
    "## Arguments\n",
    "## data -    an array of length n where array[i] is the fraction of neighbors of point i \n",
    "#            had the same class as point i.\n",
    "# numPerClass - Assumes that points from the same class are contiguous and in\n",
    "#            the same order as drumNames. Should use drumLengths for this parameter\n",
    "# calcFunc - The summary statistic you want to calcuate per class (mean, medain, etc)\n",
    "def calculateFuncPerClass(data, numPerClass, calcFunc):\n",
    "    segments = [0]+numPerClass\n",
    "    for i in range(1, len(segments)):\n",
    "        segments[i] = segments[i] + segments[i-1]\n",
    "    valuesPerClass = []\n",
    "    for i in range(len(segments)-1):\n",
    "        valuesPerClass.append(calcFunc(data[segments[i]:segments[i+1]]))\n",
    "    return valuesPerClass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "cPickle.dump(classAccuracies_HD, open(\"1024DimClassAccuracies10neighbors.np\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pairwise distance implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pairwise distances calculated 1.00153803825\n",
      "partitions calculated 2.60620808601\n",
      "knn classes calculated 11.9697771072\n",
      "pairwise distances calculated 0.9041659832\n",
      "partitions calculated 2.04635381699\n",
      "knn classes calculated 10.9746088982\n",
      "pairwise distances calculated 115.295583963\n",
      "partitions calculated 116.938618898\n",
      "knn classes calculated 125.641149998\n"
     ]
    }
   ],
   "source": [
    "#using https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.spatial.distance.cdist.html\n",
    "#and argpartition from - https://stackoverflow.com/questions/6910641/how-to-get-indices-of-n-maximum-values-in-a-numpy-array\n",
    "\n",
    "## Arguments - pointData is m x n np array, with n points of m dimensions\n",
    "# pointD numNeighbors is the number of nearest neighbors for which to compare classes\n",
    "#\n",
    "## returns - an array of length n where array[i] is the fraction of neighbors of point i \n",
    "#            had the same class as point i\n",
    "def calculateKNNClassAccuracy(pointData, numNeighbors, printTimes=False):\n",
    "    startTime = timeMod.time()\n",
    "    pairwiseDist = dist.cdist(pointData, pointData)\n",
    "    if printTimes:\n",
    "        print \"pairwise distances calculated\", timeMod.time() - startTime\n",
    "    kPartition = np.argpartition(pairwiseDist, -numNeighbors)\n",
    "    if printTimes:\n",
    "        print \"partitions calculated\", timeMod.time() - startTime\n",
    "    fracSameNeighborClasses = np.zeros((len(data)))\n",
    "    \n",
    "    for i in range(len(pairwiseDist)):\n",
    "        neighborIndexes = kPartition[i][-numNeighbors:]\n",
    "        neighbors = [data[ind] for ind in neighborIndexes]\n",
    "        \n",
    "        sampleClass = drumClasses[tuple(data[i])]\n",
    "        neighborClasses = [drumClasses[tuple(neighbor)] for neighbor in neighbors]\n",
    "        numSameNeighborClasses = len(filter(lambda c : c == sampleClass, neighborClasses))\n",
    "        fracSameNeighborClasses[i] = numSameNeighborClasses * 1.0 / numNeighbors\n",
    "    \n",
    "    if printTimes:\n",
    "        print \"knn classes calculated\", timeMod.time() - startTime\n",
    "        \n",
    "    return fracSameNeighborClasses\n",
    "\n",
    "classAccuracies_LD_TSNE = calculateKNNClassAccuracy(newData[0], numNeighbors, True)\n",
    "classAccuracies_LD_PCA = calculateKNNClassAccuracy(newData[1], numNeighbors, True)\n",
    "classAccuracies_HD = calculateKNNClassAccuracy(data, numNeighbors, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean for highDim, tsne, pca\n",
      "0.021 0.049 0.027\n",
      "\n",
      "std for highDim, tsne, pca\n",
      "0.066 0.197 0.087\n",
      "\n",
      "mean per class for highDim\n",
      "[0.0, 0.0, 0.0, 0.07, 0.033, 0.202, 0.112]\n",
      "\n",
      "std per class for highDim\n",
      "[0.272, 0.011, 0.076, 0.035, 0.0, 0.0, 0.011]\n",
      "\n",
      "mean per class for tsne\n",
      "[0.084, 0.001, 0.034, 0.003, 0.0, 0.0, 0.001]\n",
      "\n",
      "std per class for tsne\n",
      "[0.0, 0.0, 0.002, 0.046, 0.052, 0.17, 0.147]\n",
      "\n",
      "mean per class for pca\n",
      "[0.0, 0.0, 0.0, 0.092, 0.057, 0.141, 0.166]\n",
      "\n",
      "std per class for pca\n",
      "[0.0, 0.0, 0.0, 0.027, 0.05, 0.141, 0.248]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"mean for highDim, tsne, pca\"\n",
    "print round(np.mean(classAccuracies_HD), 3), round(np.mean(classAccuracies_LD_TSNE), 3), round(np.mean(classAccuracies_LD_PCA), 3)\n",
    "print\n",
    "\n",
    "print \"std for highDim, tsne, pca\"\n",
    "print round(np.std(classAccuracies_HD), 3), round(np.std(classAccuracies_LD_TSNE), 3), round(np.std(classAccuracies_LD_PCA), 3)\n",
    "print\n",
    "\n",
    "print \"mean per class for highDim\"\n",
    "print [round(n, 3) for n in calculateFuncPerClass(classAccuracies_HD, drumLengths, np.mean)]\n",
    "print \n",
    "\n",
    "print \"std per class for highDim\"\n",
    "print [round(n, 3) for n in calculateFuncPerClass(classAccuracies_LD_TSNE, drumLengths, np.std)]\n",
    "print\n",
    "\n",
    "print \"mean per class for tsne\"\n",
    "print [round(n, 3) for n in calculateFuncPerClass(classAccuracies_LD_TSNE, drumLengths, np.mean)]\n",
    "print \n",
    "\n",
    "print \"std per class for tsne\"\n",
    "print [round(n, 3) for n in calculateFuncPerClass(classAccuracies_HD, drumLengths, np.std)]\n",
    "print\n",
    "\n",
    "print \"mean per class for pca\"\n",
    "print [round(n, 3) for n in calculateFuncPerClass(classAccuracies_LD_PCA, drumLengths, np.mean)]\n",
    "print \n",
    "\n",
    "print \"std per class for pca\"\n",
    "print [round(n, 3) for n in calculateFuncPerClass(classAccuracies_LD_PCA, drumLengths, np.std)]\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[13,4,334,0 ,0 ,0],[0, 0, 0, 423,54444,63],[7333,85, 0, 0,0 ,539]])\n",
    "np.argpartition(a, -2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kd-tree imlementtaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Arguments - pointData is m x n np array, with n points of m dimensions\n",
    "# pointD numNeighbors is the number of nearest neighbors for which to compare classes\n",
    "#\n",
    "## returns - an array of length n where array[i] is the fraction of neighbors of point i \n",
    "#            had the same class as point i\n",
    "def calculateKNNClassAccuracy_kd(data, numNeighbors, printTiming=False, existingTree=None):\n",
    "    startTime = 0\n",
    "    if printTiming:\n",
    "        print \"building tree\", timeMod.time()-startTime\n",
    "    \n",
    "    if existingTree is None:\n",
    "        kdTree = scipy.spatial.KDTree(data) #takes about 2 minutes for 1024 dims\n",
    "    else:\n",
    "        kdTree = existingTree\n",
    "    \n",
    "    if printTiming:\n",
    "        print \"tree built\", timeMod.time()-startTime \n",
    "        \n",
    "    drumClasses = getClassesPerSample(data)\n",
    "    \n",
    "    return calcNeighborDistances(data, numNeighbors, kdTree, True)\n",
    "\n",
    "#helper methods below\n",
    "\n",
    "def calcNeighborDistances(pointData, numNeighbors, kdTree, printTiming=False):\n",
    "    startTime = timeMod.time()\n",
    "    if printTiming:\n",
    "        print \"calculating nearest neighbor classes\"\n",
    "    fracCorrectNeighbors = np.zeros((len(data)))\n",
    "    for i in range(len(pointData)):\n",
    "        if printTiming:\n",
    "            if i % 1000 == 0:\n",
    "                print \"evaluating neighbors for point\", i, timeMod.time() - startTime\n",
    "        neighborDistances, neighborIndexes = kdTree.query(pointData[i], numNeighbors)\n",
    "        neighbors = [data[ind] for ind in neighborIndexes]\n",
    "\n",
    "        sampleClass = drumClasses[tuple(data[i])]\n",
    "        neighborClasses = [drumClasses[tuple(neighbor)] for neighbor in neighbors]\n",
    "        numCorrectNeighborClasses = len(filter(lambda c : c == sampleClass, neighborClasses))\n",
    "        fracCorrectNeighbors[i] = numCorrectNeighborClasses * 1.0 / numNeighbors\n",
    "        \n",
    "    return fracCorrectNeighbors\n",
    "    #from here do we want - mean, median, mode, stddev of correctClass fraction?\n",
    "    #mean, median, mode, stddev of correctClass frac per class\n",
    "    #% accuracy over a thresold?\n",
    "\n",
    "def calculateFuncPerClass(data, numPerClass, calcFunc):\n",
    "    segments = [0]+numPerClass\n",
    "    for i in range(1, len(segments)):\n",
    "        segments[i] = segments[i] + segments[i-1]\n",
    "    valuesPerClass = []\n",
    "    for i in range(len(segments)-1):\n",
    "        valuesPerClass.append(calcFunc(data[segments[i]:segments[i+1]]))\n",
    "    return valuesPerClass\n",
    "\n",
    "kdTree1024Dim = scipy.spatial.KDTree(data)\n",
    "kdTree2Dim = scipy.spatial.KDTree(newData)\n",
    "\n",
    "classAccuracies_HD = calculateKNNClassAccuracy(data, numNeighbors, True, kdTree1024Dim)\n",
    "classAccuracies_LD = calculateKNNClassAccuracy(newData, numNeighbors, True, kdTree2Dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
