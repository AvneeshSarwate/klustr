{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This converts `fingerprints.npy` to `.tsv` formatted t-SNE embeddings and plots of those embeddings in the `tsne/` and `plot/` folders respectively. If you add multiple values to `perplexity` and `initial_dims` then all combinations will be computed (in parallel). Good perplexities are in the range 1-200 with the best range around 30-100. Good `initial_dims` are in the range 30 and higher, with the dimensionality of your input data being the highest possible value (e.g., a 32x32 fingerprint would have a highest possible `initial_dims` value of 32x32=1024).\n",
    "\n",
    "Change the \"mode\" to try different t-SNE variations.\n",
    "* \"fingerprints\" will only use `fingerprints.npy`\n",
    "* \"predicted_labels\" will only use `predicted_labels.npy`\n",
    "* \"predicted_encoding\" will only use `predicted_encoding.npy`\n",
    "* \"combined\" will use all of the above data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_root = 'drumData/'\n",
    "initial_dims = [30]\n",
    "perplexities = [30]\n",
    "mode = 'fingerprints'\n",
    "drumNames = [\"kick\", \"tom\", \"snare\", \"clap\", \"hi.hat\", \"ride\", \"crash\"] \n",
    "drumLengths = [] #number of items in ith class\n",
    "colors = ['#000000', '#ff0000', '#00ff00', '#0000ff', '#ffff00', '#ff00ff', '#00ffff']\n",
    "# mode = 'predicted_labels'\n",
    "# mode = 'predicted_encoding'\n",
    "# mode = 'combined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "from utils import *\n",
    "from os.path import join\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time as timeMod\n",
    "from time import mktime\n",
    "from datetime import datetime\n",
    "import scipy.spatial\n",
    "import scipy.spatial.distance as dist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2d_inspect = None\n",
    "\n",
    "def save_tsv(data, fn):\n",
    "    np.savetxt(fn, data, fmt='%.5f', delimiter='\\t')\n",
    "def tsne(data, data_root, prefix, colorMap, initial_dims=30, perplexity=30):\n",
    "    mkdir_p(data_root + 'tsne')\n",
    "    mkdir_p(data_root + 'plot')\n",
    "    \n",
    "    figsize = (16,16)\n",
    "    pointsize = 30\n",
    "    \n",
    "    struct = timeMod.localtime(time())\n",
    "    dt = datetime.fromtimestamp(mktime(struct))\n",
    "\n",
    "    X_2d = list(bh_tsne(data, initial_dims=initial_dims, perplexity=perplexity, no_dims=2))\n",
    "    X_2d = normalize(np.array(X_2d))\n",
    "    save_tsv(X_2d, join(data_root, 'tsne/{}.{}.{}.2d - {}.tsv'.format(prefix, initial_dims, perplexity, dt)))\n",
    "    \n",
    "    X_2d_inspect = X_2d\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.scatter(X_2d[:,0], X_2d[:,1], c=colorMap, s=pointsize)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(join(data_root, 'plot/{}.{}.{}_2D - {}.png'.format(prefix, initial_dims, perplexity, dt)))\n",
    "    plt.close()\n",
    "    \n",
    "    return X_2d\n",
    "#     X_3d = list(bh_tsne(data, initial_dims=initial_dims, perplexity=perplexity, no_dims=3))\n",
    "#     X_3d = normalize(np.array(X_3d))\n",
    "#     save_tsv(X_3d, join(data_root, 'tsne/{}.{}.{}.3d.tsv'.format(prefix, initial_dims, perplexity)))\n",
    "    \n",
    "#     plt.figure(figsize=figsize)\n",
    "#     plt.scatter(X_2d[:,0], X_2d[:,1], edgecolor='', s=pointsize, c=X_3d)\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(join(data_root, 'plot/{}.{}.{}_3D.png'.format(prefix, initial_dims, perplexity)))\n",
    "#     plt.close()\n",
    "    \n",
    "def concatColors(segmentList, colorList):\n",
    "    multiples = []\n",
    "    #print segmentList, colorList\n",
    "    for i in range(len(segmentList)):\n",
    "        multiples.append([colorList[i]]*segmentList[i])\n",
    "    return list(itertools.chain(*multiples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fingerprint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kick (5158, 32, 32)\n",
      "tom (422, 32, 32)\n",
      "snare (2546, 32, 32)\n",
      "clap (1324, 32, 32)\n",
      "hi.hat (159, 32, 32)\n",
      "ride (228, 32, 32)\n",
      "crash (723, 32, 32)\n",
      "[5158, 422, 2546, 1324, 159, 228, 723] ['#000000', '#ff0000', '#00ff00', '#0000ff', '#ffff00', '#ff00ff', '#00ffff']\n",
      "(10560, 1024)\n"
     ]
    }
   ],
   "source": [
    "# load and normalize any dataset we need\n",
    "if mode == 'fingerprints' or mode == 'combined':\n",
    "    drumPrints = []\n",
    "    for drum in drumNames:\n",
    "        drumPrints.append(np.load(join(data_root, drum+'_fingerprints.npy')))\n",
    "        #print drum, drumPrints[-1].shape\n",
    "    drumLengths = [drumPrint.shape[0] for drumPrint in drumPrints]\n",
    "    colorMap = concatColors(drumLengths, colors)\n",
    "    fingerprints = np.vstack(drumPrints)\n",
    "    fingerprints = fingerprints.reshape(len(fingerprints), -1)\n",
    "if mode == 'predicted_labels' or mode == 'combined':\n",
    "    predicted_labels = np.load(join(data_root, 'predicted_labels.npy'))\n",
    "    predicted_labels -= predicted_labels.min()\n",
    "    predicted_labels /= predicted_labels.max()\n",
    "if mode == 'predicted_encoding' or mode == 'combined':\n",
    "    predicted_encoding = np.load(join(data_root, 'predicted_encoding.npy'))\n",
    "    std = predicted_encoding.std(axis=0)\n",
    "    predicted_encoding = predicted_encoding[:, std > 0] / std[std > 0]\n",
    "    \n",
    "if mode == 'fingerprints':\n",
    "    data = fingerprints\n",
    "if mode == 'predicted_labels':\n",
    "    data = predicted_labels\n",
    "if mode == 'predicted_encoding':\n",
    "    data = predicted_encoding\n",
    "if mode == 'combined':\n",
    "    data = np.hstack((fingerprints, predicted_labels, predicted_encoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_dims=30, perplexity=30, 124.192649126 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process PoolWorker-104:\n",
      "Process PoolWorker-98:\n",
      "Process PoolWorker-100:\n",
      "Process PoolWorker-102:\n",
      "Process PoolWorker-101:\n",
      "Process PoolWorker-103:\n",
      "Process PoolWorker-99:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "    task = get()\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "Process PoolWorker-97:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    task = get()\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "    racquire()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    racquire()\n",
      "    racquire()\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "    return recv()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    task = get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "data = data.astype(np.float64)\n",
    "def job(params):\n",
    "    start = time()\n",
    "    data2d = tsne(data, data_root, mode, colorMap, initial_dims=params[0], perplexity=params[1])\n",
    "    print 'initial_dims={}, perplexity={}, {} seconds'.format(params[0], params[1], time() - start)\n",
    "    return data2d\n",
    "params = list(itertools.product(initial_dims, perplexities))\n",
    "pool = Pool()\n",
    "dimReducedArrays = pool.map(job, params)\n",
    "newData = dimReducedArrays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Evaluate dimensionality reductions (FIRST - select reduction method below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric calculation implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common setup \n",
    "######    create point -> class hashmap\n",
    "######   define num neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getClassesPerSample(data):\n",
    "    drumClasses = {}\n",
    "    classIndex = 0\n",
    "    for i in range(len(data)):\n",
    "        if sum(drumLengths[0:classIndex+1]) <= i:\n",
    "            classIndex += 1\n",
    "        drumClasses[tuple(data[i])] = drumNames[classIndex]\n",
    "    return drumClasses\n",
    "\n",
    "drumClasses = getClassesPerSample(data)\n",
    "numNeighbors = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kd-tree imlementtaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculateKNNClassAccuracy(data, numNeighbors, printTiming=False, existingTree=None):\n",
    "    startTime = 0\n",
    "    if printTiming:\n",
    "        print \"building tree\", timeMod.time()-startTime\n",
    "    \n",
    "    if existingTree is None:\n",
    "        kdTree = scipy.spatial.KDTree(data) #takes about 2 minutes for 1024 dims\n",
    "    else:\n",
    "        kdTree = existingTree\n",
    "    \n",
    "    if printTiming:\n",
    "        print \"tree built\", timeMod.time()-startTime \n",
    "        \n",
    "    drumClasses = getClassesPerSample(data)\n",
    "    \n",
    "    return calcNeighborDistances(data, numNeighbors, kdTree, True)\n",
    "\n",
    "        \n",
    "def calcNeighborDistances(pointData, numNeighbors, kdTree, printTiming=False):\n",
    "    startTime = timeMod.time()\n",
    "    if printTiming:\n",
    "        print \"calculating nearest neighbor classes\"\n",
    "    fracCorrectNeighbors = np.zeros((len(data)))\n",
    "    for i in range(len(pointData)):\n",
    "        if printTiming:\n",
    "            if i % 1000 == 0:\n",
    "                print \"evaluating neighbors for point\", i, timeMod.time() - startTime\n",
    "        neighborDistances, neighborIndexes = kdTree.query(pointData[i], numNeighbors)\n",
    "        neighbors = [data[ind] for ind in neighborIndexes]\n",
    "\n",
    "        sampleClass = drumClasses[tuple(data[i])]\n",
    "        neighborClasses = [drumClasses[tuple(neighbor)] for neighbor in neighbors]\n",
    "        numCorrectNeighborClasses = len(filter(lambda c : c == sampleClass, neighborClasses))\n",
    "        fracCorrectNeighbors[i] = numCorrectNeighborClasses * 1.0 / numNeighbors\n",
    "        \n",
    "    return fracCorrectNeighbors\n",
    "    #from here do we want - mean, median, mode, stddev of correctClass fraction?\n",
    "    #mean, median, mode, stddev of correctClass frac per class\n",
    "    #% accuracy over a thresold?\n",
    "\n",
    "def calculateFuncPerClass(data, numPerClass, calcFunc):\n",
    "    segments = [0]+numPerClass\n",
    "    for i in range(1, len(segments)):\n",
    "        segments[i] = segments[i] + segments[i-1]\n",
    "    valuesPerClass = []\n",
    "    for i in range(len(segments)-1):\n",
    "        valuesPerClass.append(calcFunc(data[segments[i]:segments[i+1]]))\n",
    "    return valuesPerClass\n",
    "\n",
    "kdTree1024Dim = scipy.spatial.KDTree(data)\n",
    "kdTree2Dim = scipy.spatial.KDTree(newData)\n",
    "\n",
    "classAccuracies_HD = calculateKNNClassAccuracy(data, numNeighbors, True, kdTree1024Dim)\n",
    "classAccuracies_LD = calculateKNNClassAccuracy(newData, numNeighbors, True, kdTree2Dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle\n",
    "cPickle.dump(classAccuracies_HD, open(\"1024DimClassAccuracies10neighbors.np\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pairwise distance implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pairwise distances calculated 0.81754899025\n",
      "partitions calculated 1.82683610916\n",
      "knn classes calculated 10.0848770142\n",
      "pairwise distances calculated 106.18317008\n",
      "partitions calculated 107.166157007\n",
      "knn classes calculated 115.466816902\n"
     ]
    }
   ],
   "source": [
    "#using https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.spatial.distance.cdist.html\n",
    "#and argpartition from - https://stackoverflow.com/questions/6910641/how-to-get-indices-of-n-maximum-values-in-a-numpy-array\n",
    "\n",
    "def calculateKNNClassAccuracy(pointData, numNeighbors, printTimes=False):\n",
    "    startTime = timeMod.time()\n",
    "    pairwiseDist = dist.cdist(pointData, pointData)\n",
    "    if printTimes:\n",
    "        print \"pairwise distances calculated\", timeMod.time() - startTime\n",
    "    kPartition = np.argpartition(pairwiseDist, -numNeighbors)\n",
    "    if printTimes:\n",
    "        print \"partitions calculated\", timeMod.time() - startTime\n",
    "    fracSameNeighborClasses = np.zeros((len(data)))\n",
    "    \n",
    "    for i in range(len(pairwiseDist)):\n",
    "        neighborIndexes = kPartition[i][-numNeighbors:]\n",
    "        neighbors = [data[ind] for ind in neighborIndexes]\n",
    "        \n",
    "        sampleClass = drumClasses[tuple(data[i])]\n",
    "        neighborClasses = [drumClasses[tuple(neighbor)] for neighbor in neighbors]\n",
    "        numSameNeighborClasses = len(filter(lambda c : c == sampleClass, neighborClasses))\n",
    "        fracSameNeighborClasses[i] = numSameNeighborClasses * 1.0 / numNeighbors\n",
    "    \n",
    "    if printTimes:\n",
    "        print \"knn classes calculated\", timeMod.time() - startTime\n",
    "        \n",
    "    return fracSameNeighborClasses\n",
    "\n",
    "classAccuracies_LD = calculateKNNClassAccuracy(newData, numNeighbors, True)\n",
    "classAccuracies_HD = calculateKNNClassAccuracy(data, numNeighbors, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5, 1, 3, 0, 2],\n",
       "       [2, 0, 1, 5, 3, 4],\n",
       "       [4, 2, 1, 3, 5, 0]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[13,4,334,0 ,0 ,0],[0, 0, 0, 423,54444,63],[7333,85, 0, 0,0 ,539]])\n",
    "np.argpartition(a, -2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
