{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This converts `fingerprints.npy` to `.tsv` formatted t-SNE embeddings and plots of those embeddings in the `tsne/` and `plot/` folders respectively. If you add multiple values to `perplexity` and `initial_dims` then all combinations will be computed (in parallel). Good perplexities are in the range 1-200 with the best range around 30-100. Good `initial_dims` are in the range 30 and higher, with the dimensionality of your input data being the highest possible value (e.g., a 32x32 fingerprint would have a highest possible `initial_dims` value of 32x32=1024).\n",
    "\n",
    "Change the \"mode\" to try different t-SNE variations.\n",
    "* \"fingerprints\" will only use `fingerprints.npy`\n",
    "* \"predicted_labels\" will only use `predicted_labels.npy`\n",
    "* \"predicted_encoding\" will only use `predicted_encoding.npy`\n",
    "* \"combined\" will use all of the above data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to do:\n",
    "- Normalize audio\n",
    "- Scale the spectrogram\n",
    "- do all of the data cleaning so different factors between sample banks don't bias the feature extraction\n",
    "- make sure to baseline this against traditional feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "from utils import *\n",
    "from os.path import join\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time as timeMod\n",
    "from time import mktime\n",
    "from datetime import datetime\n",
    "import scipy.spatial\n",
    "import scipy.spatial.distance as dist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_root = 'drumData/'\n",
    "initial_dims = [30]\n",
    "perplexities = [30]\n",
    "mode = 'fingerprints'\n",
    "drumNames = pickle.load(open(data_root+'drumNames.pickle'))\n",
    "drumLengths = pickle.load(open(data_root+'drumLengths.pickle'))\n",
    "colors = ['#000000', '#ff0000', '#00ff00', '#0000ff', '#ffff00', '#ff00ff', '#00ffff']\n",
    "# mode = 'predicted_labels'\n",
    "# mode = 'predicted_encoding'\n",
    "# mode = 'combined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2d_inspect = None\n",
    "\n",
    "def save_tsv(data, fn):\n",
    "    np.savetxt(fn, data, fmt='%.5f', delimiter='\\t')\n",
    "def tsne(data, data_root, prefix, colorMap, initial_dims=30, perplexity=30):\n",
    "    mkdir_p(data_root + 'tsne')\n",
    "    mkdir_p(data_root + 'plot')\n",
    "    \n",
    "    figsize = (16,16)\n",
    "    pointsize = 30\n",
    "    \n",
    "    struct = timeMod.localtime(time())\n",
    "    dt = datetime.fromtimestamp(mktime(struct))\n",
    "\n",
    "    X_2d = list(bh_tsne(data, initial_dims=initial_dims, perplexity=perplexity, no_dims=2))\n",
    "    X_2d = normalize(np.array(X_2d))\n",
    "    save_tsv(X_2d, join(data_root, 'tsne/{}.{}.{}.2d - {}.tsv'.format(prefix, initial_dims, perplexity, dt)))\n",
    "    \n",
    "    X_2d_inspect = X_2d\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.scatter(X_2d[:,0], X_2d[:,1], c=colorMap, s=pointsize)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(join(data_root, 'plot/{}.{}.{}_2D - {}.png'.format(prefix, initial_dims, perplexity, dt)))\n",
    "    plt.close()\n",
    "    \n",
    "    return X_2d\n",
    "#     X_3d = list(bh_tsne(data, initial_dims=initial_dims, perplexity=perplexity, no_dims=3))\n",
    "#     X_3d = normalize(np.array(X_3d))\n",
    "#     save_tsv(X_3d, join(data_root, 'tsne/{}.{}.{}.3d.tsv'.format(prefix, initial_dims, perplexity)))\n",
    "    \n",
    "#     plt.figure(figsize=figsize)\n",
    "#     plt.scatter(X_2d[:,0], X_2d[:,1], edgecolor='', s=pointsize, c=X_3d)\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(join(data_root, 'plot/{}.{}.{}_3D.png'.format(prefix, initial_dims, perplexity)))\n",
    "#     plt.close()\n",
    "    \n",
    "def concatColors(segmentList, colorList):\n",
    "    multiples = []\n",
    "    #print segmentList, colorList\n",
    "    for i in range(len(segmentList)):\n",
    "        multiples.append([colorList[i]]*segmentList[i])\n",
    "    return list(itertools.chain(*multiples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fingerprint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5158, 422, 2546, 1324, 159, 228, 723] ['#000000', '#ff0000', '#00ff00', '#0000ff', '#ffff00', '#ff00ff', '#00ffff']\n"
     ]
    }
   ],
   "source": [
    "# load and normalize any dataset we need\n",
    "if mode == 'fingerprints' or mode == 'combined':\n",
    "    drumPrints = []\n",
    "    for drum in drumNames:\n",
    "        drumPrints.append(np.load(join(data_root, drum+'_fingerprints.npy')))\n",
    "        #print drum, drumPrints[-1].shape\n",
    "    drumLengths = [drumPrint.shape[0] for drumPrint in drumPrints]\n",
    "    colorMap = concatColors(drumLengths, colors)\n",
    "    fingerprints = np.vstack(drumPrints)\n",
    "    fingerprints = fingerprints.reshape(len(fingerprints), -1)\n",
    "if mode == 'predicted_labels' or mode == 'combined':\n",
    "    predicted_labels = np.load(join(data_root, 'predicted_labels.npy'))\n",
    "    predicted_labels -= predicted_labels.min()\n",
    "    predicted_labels /= predicted_labels.max()\n",
    "if mode == 'predicted_encoding' or mode == 'combined':\n",
    "    predicted_encoding = np.load(join(data_root, 'predicted_encoding.npy'))\n",
    "    std = predicted_encoding.std(axis=0)\n",
    "    predicted_encoding = predicted_encoding[:, std > 0] / std[std > 0]\n",
    "    \n",
    "if mode == 'fingerprints':\n",
    "    data = fingerprints\n",
    "if mode == 'predicted_labels':\n",
    "    data = predicted_labels\n",
    "if mode == 'predicted_encoding':\n",
    "    data = predicted_encoding\n",
    "if mode == 'combined':\n",
    "    data = np.hstack((fingerprints, predicted_labels, predicted_encoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.astype(np.float64)\n",
    "def job(params):\n",
    "    start = time()\n",
    "    data2d = tsne(data, data_root, mode, colorMap, initial_dims=params[0], perplexity=params[1])\n",
    "    print 'initial_dims={}, perplexity={}, {} seconds'.format(params[0], params[1], time() - start)\n",
    "    return data2d\n",
    "params = list(itertools.product(initial_dims, perplexities))\n",
    "pool = Pool()\n",
    "dimReducedArrays = pool.map(job, params)\n",
    "newData = dimReducedArrays[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric calculation implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create point -> class hashmap\n",
    "def getClassesPerSample(data):\n",
    "    drumClasses = {}\n",
    "    classIndex = 0\n",
    "    for i in range(len(data)):\n",
    "        if sum(drumLengths[0:classIndex+1]) <= i:\n",
    "            classIndex += 1\n",
    "        drumClasses[tuple(data[i])] = drumNames[classIndex]\n",
    "    return drumClasses\n",
    "\n",
    "drumClasses = getClassesPerSample(data)\n",
    "\n",
    "numNeighbors = 10\n",
    "\n",
    "## Arguments\n",
    "## data -    an array of length n where array[i] is the fraction of neighbors of point i \n",
    "#            had the same class as point i.\n",
    "# numPerClass - Assumes that points from the same class are contiguous and in\n",
    "#            the same order as drumNames. Should use drumLengths for this parameter\n",
    "# calcFunc - The summary statistic you want to calcuate per class (mean, medain, etc)\n",
    "def calculateFuncPerClass(data, numPerClass, calcFunc):\n",
    "    segments = [0]+numPerClass\n",
    "    for i in range(1, len(segments)):\n",
    "        segments[i] = segments[i] + segments[i-1]\n",
    "    valuesPerClass = []\n",
    "    for i in range(len(segments)-1):\n",
    "        valuesPerClass.append(calcFunc(data[segments[i]:segments[i+1]]))\n",
    "    return valuesPerClass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kd-tree imlementtaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Arguments - pointData is m x n np array, with n points of m dimensions\n",
    "# pointD numNeighbors is the number of nearest neighbors for which to compare classes\n",
    "#\n",
    "## returns - an array of length n where array[i] is the fraction of neighbors of point i \n",
    "#            had the same class as point i\n",
    "def calculateKNNClassAccuracy_kd(data, numNeighbors, printTiming=False, existingTree=None):\n",
    "    startTime = 0\n",
    "    if printTiming:\n",
    "        print \"building tree\", timeMod.time()-startTime\n",
    "    \n",
    "    if existingTree is None:\n",
    "        kdTree = scipy.spatial.KDTree(data) #takes about 2 minutes for 1024 dims\n",
    "    else:\n",
    "        kdTree = existingTree\n",
    "    \n",
    "    if printTiming:\n",
    "        print \"tree built\", timeMod.time()-startTime \n",
    "        \n",
    "    drumClasses = getClassesPerSample(data)\n",
    "    \n",
    "    return calcNeighborDistances(data, numNeighbors, kdTree, True)\n",
    "\n",
    "#helper methods below\n",
    "\n",
    "def calcNeighborDistances(pointData, numNeighbors, kdTree, printTiming=False):\n",
    "    startTime = timeMod.time()\n",
    "    if printTiming:\n",
    "        print \"calculating nearest neighbor classes\"\n",
    "    fracCorrectNeighbors = np.zeros((len(data)))\n",
    "    for i in range(len(pointData)):\n",
    "        if printTiming:\n",
    "            if i % 1000 == 0:\n",
    "                print \"evaluating neighbors for point\", i, timeMod.time() - startTime\n",
    "        neighborDistances, neighborIndexes = kdTree.query(pointData[i], numNeighbors)\n",
    "        neighbors = [data[ind] for ind in neighborIndexes]\n",
    "\n",
    "        sampleClass = drumClasses[tuple(data[i])]\n",
    "        neighborClasses = [drumClasses[tuple(neighbor)] for neighbor in neighbors]\n",
    "        numCorrectNeighborClasses = len(filter(lambda c : c == sampleClass, neighborClasses))\n",
    "        fracCorrectNeighbors[i] = numCorrectNeighborClasses * 1.0 / numNeighbors\n",
    "        \n",
    "    return fracCorrectNeighbors\n",
    "    #from here do we want - mean, median, mode, stddev of correctClass fraction?\n",
    "    #mean, median, mode, stddev of correctClass frac per class\n",
    "    #% accuracy over a thresold?\n",
    "\n",
    "def calculateFuncPerClass(data, numPerClass, calcFunc):\n",
    "    segments = [0]+numPerClass\n",
    "    for i in range(1, len(segments)):\n",
    "        segments[i] = segments[i] + segments[i-1]\n",
    "    valuesPerClass = []\n",
    "    for i in range(len(segments)-1):\n",
    "        valuesPerClass.append(calcFunc(data[segments[i]:segments[i+1]]))\n",
    "    return valuesPerClass\n",
    "\n",
    "kdTree1024Dim = scipy.spatial.KDTree(data)\n",
    "kdTree2Dim = scipy.spatial.KDTree(newData)\n",
    "\n",
    "classAccuracies_HD = calculateKNNClassAccuracy(data, numNeighbors, True, kdTree1024Dim)\n",
    "classAccuracies_LD = calculateKNNClassAccuracy(newData, numNeighbors, True, kdTree2Dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "cPickle.dump(classAccuracies_HD, open(\"1024DimClassAccuracies10neighbors.np\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pairwise distance implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pairwise distances calculated 0.81754899025\n",
      "partitions calculated 1.82683610916\n",
      "knn classes calculated 10.0848770142\n",
      "pairwise distances calculated 106.18317008\n",
      "partitions calculated 107.166157007\n",
      "knn classes calculated 115.466816902\n"
     ]
    }
   ],
   "source": [
    "#using https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.spatial.distance.cdist.html\n",
    "#and argpartition from - https://stackoverflow.com/questions/6910641/how-to-get-indices-of-n-maximum-values-in-a-numpy-array\n",
    "\n",
    "## Arguments - pointData is m x n np array, with n points of m dimensions\n",
    "# pointD numNeighbors is the number of nearest neighbors for which to compare classes\n",
    "#\n",
    "## returns - an array of length n where array[i] is the fraction of neighbors of point i \n",
    "#            had the same class as point i\n",
    "def calculateKNNClassAccuracy_pairwise(pointData, numNeighbors, printTimes=False):\n",
    "    startTime = timeMod.time()\n",
    "    pairwiseDist = dist.cdist(pointData, pointData)\n",
    "    if printTimes:\n",
    "        print \"pairwise distances calculated\", timeMod.time() - startTime\n",
    "    kPartition = np.argpartition(pairwiseDist, -numNeighbors)\n",
    "    if printTimes:\n",
    "        print \"partitions calculated\", timeMod.time() - startTime\n",
    "    fracSameNeighborClasses = np.zeros((len(data)))\n",
    "    \n",
    "    for i in range(len(pairwiseDist)):\n",
    "        neighborIndexes = kPartition[i][-numNeighbors:]\n",
    "        neighbors = [data[ind] for ind in neighborIndexes]\n",
    "        \n",
    "        sampleClass = drumClasses[tuple(data[i])]\n",
    "        neighborClasses = [drumClasses[tuple(neighbor)] for neighbor in neighbors]\n",
    "        numSameNeighborClasses = len(filter(lambda c : c == sampleClass, neighborClasses))\n",
    "        fracSameNeighborClasses[i] = numSameNeighborClasses * 1.0 / numNeighbors\n",
    "    \n",
    "    if printTimes:\n",
    "        print \"knn classes calculated\", timeMod.time() - startTime\n",
    "        \n",
    "    return fracSameNeighborClasses\n",
    "\n",
    "classAccuracies_LD = calculateKNNClassAccuracy(newData, numNeighbors, True)\n",
    "classAccuracies_HD = calculateKNNClassAccuracy(data, numNeighbors, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5, 1, 3, 0, 2],\n",
       "       [2, 0, 1, 5, 3, 4],\n",
       "       [4, 2, 1, 3, 5, 0]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[13,4,334,0 ,0 ,0],[0, 0, 0, 423,54444,63],[7333,85, 0, 0,0 ,539]])\n",
    "np.argpartition(a, -2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
