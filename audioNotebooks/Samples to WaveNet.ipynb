{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lamtharnhantrakul/anaconda/envs/klustr/lib/python2.7/site-packages/magenta/models/nsynth/wavenet/masked.py:116: __init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import umap\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from magenta.models.nsynth import utils\n",
    "from magenta.models.nsynth.wavenet import fastgen\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "np.random.seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_root = 'drumData'\n",
    "n_fft = 1024\n",
    "hop_length = n_fft/4\n",
    "use_logamp = False # boost the brightness of quiet sounds\n",
    "reduce_rows = 10 # how many frequency bands to average into one\n",
    "reduce_cols = 1 # how many time steps to average into one\n",
    "crop_rows = 32 # limit how many frequency bands to use\n",
    "crop_cols = 32 # limit how many time steps to use\n",
    "limit = None # set this to 100 to only process 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.17 ms, sys: 334 ms, total: 336 ms\n",
      "Wall time: 496 ms\n",
      "CPU times: user 549 µs, sys: 25.7 ms, total: 26.3 ms\n",
      "Wall time: 47.5 ms\n",
      "CPU times: user 1.78 ms, sys: 166 ms, total: 168 ms\n",
      "Wall time: 448 ms\n",
      "CPU times: user 1.46 ms, sys: 87.5 ms, total: 89 ms\n",
      "Wall time: 128 ms\n",
      "CPU times: user 1.01 ms, sys: 12.8 ms, total: 13.8 ms\n",
      "Wall time: 35.9 ms\n",
      "CPU times: user 1.73 ms, sys: 16.9 ms, total: 18.7 ms\n",
      "Wall time: 34.3 ms\n",
      "CPU times: user 926 µs, sys: 49.7 ms, total: 50.7 ms\n",
      "Wall time: 79.8 ms\n",
      "(5158, 12000)\n",
      "(422, 12000)\n",
      "(2546, 12000)\n",
      "(1324, 12000)\n",
      "(159, 12000)\n",
      "(228, 12000)\n",
      "(723, 12000)\n"
     ]
    }
   ],
   "source": [
    "drumNames = [\"kick\", \"tom\", \"snare\", \"clap\", \"hi.hat\", \"ride\", \"crash\"]\n",
    "drumFingerPrints = {}\n",
    "drumSamples = {}\n",
    "for d in drumNames:\n",
    "    %time drumSamples[d] = np.load(join(data_root, d+'_samples.npy'))\n",
    "for d in drumNames:\n",
    "    print (drumSamples[d].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wavenet_encode(wave_files):\n",
    "    '''\n",
    "    neural_sample_rate = 16000\n",
    "    audio = utils.load_audio(file_path, \n",
    "                             sample_length=400000, \n",
    "                             sr=neural_sample_rate)\n",
    "    '''\n",
    "    encoding = fastgen.encode(wave_files, './wavenet-ckpt/model.ckpt-200000', 12000)\n",
    "    \n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000,)\n",
      "(5158, 12000)\n"
     ]
    }
   ],
   "source": [
    "crashes = drumSamples[\"crash\"]\n",
    "kicks = drumSamples[\"kick\"]\n",
    "\n",
    "sample_kick = kicks[0]\n",
    "sample_crash = crashes[0]\n",
    "print(sample_kick.shape)\n",
    "print(kicks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./wavenet-ckpt/model.ckpt-200000\n"
     ]
    }
   ],
   "source": [
    "wavenet_kick = wavenet_encode(sample_kick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 23, 16)\n",
      "15.8841\n",
      "-8.46548\n"
     ]
    }
   ],
   "source": [
    "print(wavenet_kick.shape)\n",
    "print(np.max(wavenet_kick))\n",
    "print(np.min(wavenet_kick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./wavenet-ckpt/model.ckpt-200000\n",
      "('hi.hat', (159, 23, 16))\n",
      "INFO:tensorflow:Restoring parameters from ./wavenet-ckpt/model.ckpt-200000\n",
      "('ride', (228, 23, 16))\n",
      "INFO:tensorflow:Restoring parameters from ./wavenet-ckpt/model.ckpt-200000\n",
      "('crash', (723, 23, 16))\n"
     ]
    }
   ],
   "source": [
    "small_drumset = [\"tom\",\"hi.hat\", \"ride\", \"crash\"]\n",
    "large_drumset = [\"kick\", \"snare\", \"clap\"]\n",
    "\n",
    "for drum_name in small_drumset: \n",
    "    wavenet_features = wavenet_encode(drumSamples[drum_name])\n",
    "    print (drum_name, wavenet_features.shape)  \n",
    "    file_path = './drumEmbeddings/' + drum_name + '_wavenet.npy'\n",
    "    np.save(file_path, wavenet_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from magenta.models.nsynth import utils\n",
    "from magenta.models.nsynth.wavenet.h512_bo16 import Config\n",
    "from magenta.models.nsynth.wavenet.h512_bo16 import FastGenerationConfig\n",
    "\n",
    "def custom_encode(wav_data, checkpoint_path, drum_name, sample_length=64000):\n",
    "    batch_size = 1\n",
    "    samples_wavenet = []\n",
    "    num_samples = wav_data.shape[0]\n",
    "    # Load up the model for encoding and find the encoding of \"wav_data\"\n",
    "    session_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    with tf.Graph().as_default(), tf.Session(config=session_config) as sess:\n",
    "        hop_length = Config().ae_hop_length\n",
    "        net = testload_nsynth(batch_size=batch_size, sample_length=11776)  # hardcore to 11776 for samples of length 12000\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "        \n",
    "        for i in tqdm(range(num_samples)):\n",
    "            sample = wav_data[i]\n",
    "            sample = np.expand_dims(sample,0)\n",
    "            sample, sample_length = utils.trim_for_encoding(sample, sample_length,hop_length)\n",
    "            encodings = sess.run(net[\"encoding\"], feed_dict={net[\"X\"]: sample})\n",
    "            encodings = encodings.reshape(-1,16)\n",
    "            samples_wavenet.append(encodings)\n",
    "        samples_wavenet = np.asarray(samples_wavenet)\n",
    "        \n",
    "        file_path = './drumEmbeddings/' + drum_name + '_wavenet.npy'\n",
    "        np.save(file_path, samples_wavenet)\n",
    "        print (drum_name, samples_wavenet.shape) \n",
    "        \n",
    "def testload_nsynth(batch_size=1, sample_length=64000):\n",
    "    \"\"\"Load the NSynth autoencoder network.\n",
    "    Args:\n",
    "    batch_size: Batch size number of observations to process. [1]\n",
    "    sample_length: Number of samples in the input audio. [64000]\n",
    "    Returns:\n",
    "    graph: The network as a dict with input placeholder in {\"X\"}\n",
    "    \"\"\"\n",
    "    config = Config()\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        x = tf.placeholder(tf.float32, shape=[batch_size, sample_length])\n",
    "        graph = config.build({\"wav\": x}, is_training=False)\n",
    "        graph.update({\"X\": x})\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#custom_encode(kicks[0:20], './wavenet-ckpt/model.ckpt-200000', 12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./wavenet-ckpt/model.ckpt-200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:14<00:00,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('clap', (5, 23, 16))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "drum_name = \"clap\"\n",
    "custom_encode(kicks[:5], './wavenet-ckpt/model.ckpt-200000',drum_name, 12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
